# Task 4.1: Implement LLM Analyzer

**Date:** 2026-01-19
**Tool:** Claude Code
**Task:** Implement GPT-4o based log analyzer

## Summary

Implemented the LLM analyzer module that uses OpenAI's GPT-4o model to analyze Sentry logs and provide probable causes with suggested customer responses.

## Key Changes

### Files Created
- `backend/analyzer.py` - Main LLM analyzer implementation
- `backend/test_analyzer.py` - Comprehensive test suite (19 tests)

### Files Modified
- `backend/config.py` - Updated to use lowercase property names (sentry_auth_token, openai_api_key, etc.)
- `backend/sentry_client.py` - Updated to use lowercase config properties
- `backend/main.py` - Updated to use lowercase config properties
- `backend/test_config.py` - Updated tests to match lowercase property names

## Implementation Details

### analyzer.py Features
1. **System Prompt** - Implements exact prompt from Tech Spec lines 233-252
2. **User Prompt Construction** - Builds prompt with workflow docs, known errors, Sentry events, and problem description
3. **OpenAI Integration**:
   - Uses AsyncOpenAI client with GPT-4o model
   - JSON mode enabled via response_format parameter
   - Temperature: 0.7 (balanced creativity and consistency)
   - Max tokens: 1500 (comprehensive responses)
4. **Retry Logic** - Uses tenacity library with exponential backoff (3 attempts, 2-10s wait)
5. **Error Handling**:
   - Custom exceptions: LLMAnalysisError, LLMResponseFormatError, LLMAPIError
   - Graceful handling of OpenAI API errors
   - Detailed validation error messages
6. **Response Validation**:
   - Validates required fields (causes, suggested_response, logs_summary)
   - Validates causes array structure (rank, cause, explanation, confidence)
   - Validates confidence levels (high/medium/low)
   - Ensures non-empty string fields

### Test Coverage
Created comprehensive test suite with 19 tests covering:
- User prompt construction
- LLM response validation (valid and invalid cases)
- OpenAI API calls with retry logic
- Successful analysis flow
- Analysis with no Sentry events
- Malformed JSON handling
- OpenAI API error handling
- Prompt construction verification

All tests passing ✓

### Config Property Updates
Changed all config properties from UPPERCASE to lowercase for consistency:
- `SENTRY_AUTH_TOKEN` → `sentry_auth_token`
- `SENTRY_ORG` → `sentry_org`
- `SENTRY_PROJECT` → `sentry_project`
- `OPENAI_API_KEY` → `openai_api_key`
- `SLACK_BOT_TOKEN` → `slack_bot_token`
- `SLACK_SIGNING_SECRET` → `slack_signing_secret`
- `APP_PASSWORD` → `app_password`
- `ALLOWED_ORIGINS` → `allowed_origins`

## Tasks Completed
- ✅ Task 4.1: Implement LLM Analyzer

## Acceptance Criteria Met
- [x] `analyzer.py` implements LLM analysis
- [x] Uses OpenAI GPT-4o model
- [x] Loads workflow.md and known_errors.md (via function parameters)
- [x] Constructs proper system and user prompts
- [x] Parses JSON response from LLM
- [x] Handles LLM errors gracefully

## Tests Required (All Passing)
- [x] Test successful analysis
- [x] Test with no Sentry events
- [x] Test with malformed LLM response
- [x] Test with OpenAI API error
- [x] Test prompt construction

## Testing Results
```
test_analyzer.py::TestConstructUserPrompt::test_construct_user_prompt_includes_all_sections PASSED
test_analyzer.py::TestConstructUserPrompt::test_construct_user_prompt_includes_json_format PASSED
test_analyzer.py::TestValidateLLMResponse::test_validate_valid_response PASSED
test_analyzer.py::TestValidateLLMResponse::test_validate_missing_causes PASSED
test_analyzer.py::TestValidateLLMResponse::test_validate_missing_suggested_response PASSED
test_analyzer.py::TestValidateLLMResponse::test_validate_missing_logs_summary PASSED
test_analyzer.py::TestValidateLLMResponse::test_validate_causes_not_array PASSED
test_analyzer.py::TestValidateLLMResponse::test_validate_cause_missing_fields PASSED
test_analyzer.py::TestValidateLLMResponse::test_validate_empty_suggested_response PASSED
test_analyzer.py::TestValidateLLMResponse::test_validate_empty_logs_summary PASSED
test_analyzer.py::TestValidateLLMResponse::test_validate_invalid_confidence_level PASSED
test_analyzer.py::TestCallOpenAIAPI::test_successful_api_call PASSED
test_analyzer.py::TestCallOpenAIAPI::test_api_call_with_empty_response PASSED
test_analyzer.py::TestCallOpenAIAPI::test_api_call_with_exception PASSED
test_analyzer.py::TestAnalyzeLogs::test_successful_analysis PASSED
test_analyzer.py::TestAnalyzeLogs::test_analysis_with_no_sentry_events PASSED
test_analyzer.py::TestAnalyzeLogs::test_analysis_with_malformed_json PASSED
test_analyzer.py::TestAnalyzeLogs::test_analysis_with_openai_api_error PASSED
test_analyzer.py::TestAnalyzeLogs::test_prompt_construction_in_analysis PASSED

19 passed in 12.80s
```

Also verified that all other tests still pass after config changes:
- test_config.py: 9 tests passing
- test_main.py: 6 tests passing
- test_auth.py: 5 tests passing
- test_sentry_client.py: 21 tests passing

## Next Steps
1. Task 3.2: Format Sentry Events for LLM (to prepare events for analyzer)
2. Task 4.2: Validate and Structure LLM Response (additional response processing)
3. Task 3.3/4.3: Wire everything together in the /analyze endpoint
